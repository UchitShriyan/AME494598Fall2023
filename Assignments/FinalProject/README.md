## Global Gesture-Controlled Car Using Arduino Nano BLE 33 Sense and MQTT Protocol

### Overview
This project showcases the innovative integration of IoT and machine learning technologies to control a car remotely using intuitive hand gestures. Utilizing Arduino Nano 33 BLE Sense for gesture recognition and Arduino Nano 33 IoT for MQTT-based communication, this system represents a significant advancement in remote interaction technology.

### Features
Gesture Recognition: Utilizes Arduino Nano 33 BLE Sense for detecting specific hand gestures.
Real-Time Communication: Employs MQTT protocol for efficient, real-time data transmission between the controller and the car.
Robust Vehicle Control: Integrates WeMos D1 R1 microcontroller with motor drivers and motors for precise vehicle maneuvering.

### Applications
This technology extends beyond remote control systems, offering potential applications in various fields where remote and intuitive control is beneficial, such as in hazardous environments or inaccessible locations. It could revolutionize the way we interact with machines in sectors like healthcare for remote surgeries, in space exploration for controlling rovers, and in the automotive industry for enhanced driver-assist systems. Its adaptability and ease of use make it a promising tool for improving accessibility and interaction in diverse applications.

### Demonstration
Watch our project in action and see how the gesture-controlled car operates seamlessly in a real-world setting. Check out our demo video here: 
[![Video](https://img.youtube.com/vi/zzCrpVZPffA/maxresdefault.jpg)](https://youtu.be/zzCrpVZPffA)

### Future Work
The project lays the groundwork for future enhancements, including further refinement of vehicle autonomy and exploration into advanced AIoT systems. Future developments may focus on integrating more complex gesture recognition algorithms, enhancing the system's responsiveness in varied environments, and scaling the technology for broader applications. We aim to continuously improve the user experience and expand the capabilities of gesture-controlled systems in various sectors.

### Acknowledgments
Special thanks to Professor Tejaswi Linge Gowda, instructor for AME 598, course for their guidance and support in this endeavor.
